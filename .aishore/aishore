#!/bin/bash
# aishore - AI Sprint Runner CLI
# A self-contained sprint orchestration tool for Claude Code
#
# Usage: .aishore/aishore <command> [options]
#
# Commands:
#   run [count|ID]  Run sprints (default: 1) or specific item by ID
#   groom           Groom bugs/tech debt (Tech Lead)
#   groom --backlog Groom features (Product Owner)
#   review          Architecture review
#   metrics         Show sprint metrics
#   update          Update aishore from upstream (with checksum verification)
#   checksums       Regenerate checksums.sha256
#   init            Setup wizard (prerequisites, config, backlog)
#   help            Show this help

set -euo pipefail

AISHORE_TMPDIR=""
AISHORE_DID_STASH=""
cleanup_exit() {
    # Restore stashed changes on unexpected exit
    if [[ "$AISHORE_DID_STASH" == "true" ]]; then
        git stash pop >/dev/null 2>&1 || true
        AISHORE_DID_STASH=""
    fi
    [[ -n "$AISHORE_TMPDIR" && -d "$AISHORE_TMPDIR" ]] && rm -rf "$AISHORE_TMPDIR"
    return 0
}
trap cleanup_exit EXIT

ensure_tmpdir() {
    [[ -z "$AISHORE_TMPDIR" ]] && AISHORE_TMPDIR=$(mktemp -d "${TMPDIR:-/tmp}/aishore.XXXXXX")
    echo "$AISHORE_TMPDIR"
}

# ============================================================================
# PATHS
# ============================================================================

AISHORE_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$AISHORE_ROOT")"

# Version: read from VERSION file if present, otherwise fall back to inline
if [[ -f "$PROJECT_ROOT/VERSION" ]]; then
    AISHORE_VERSION=$(cat "$PROJECT_ROOT/VERSION")
else
    AISHORE_VERSION="0.1.6"
fi

# Tool paths (in .aishore/ - can be updated)
CONFIG_FILE="$AISHORE_ROOT/config.yaml"
AGENTS_DIR="$AISHORE_ROOT/agents"
DATA_DIR="$AISHORE_ROOT/data"
STATUS_DIR="$DATA_DIR/status"
LOGS_DIR="$DATA_DIR/logs"

# User content paths (at project level - never touched by update)
BACKLOG_DIR="$PROJECT_ROOT/backlog"
ARCHIVE_DIR="$BACKLOG_DIR/archive"

# ============================================================================
# DEFAULTS — set first, config.yaml overrides, env vars win last
# ============================================================================

MODEL_PRIMARY="claude-opus-4-6"
MODEL_FAST="claude-sonnet-4-6"
AGENT_TIMEOUT="3600"
VALIDATE_CMD=""
VALIDATE_TIMEOUT="120"
NOTIFY_CMD=""

# Default permission sets per agent role
PERMS_DEVELOPER="Bash(git:*),Edit,Write,Read,Glob,Grep"
PERMS_VALIDATOR="Bash(git:*),Read,Glob,Grep"
PERMS_REVIEWER="Read,Glob,Grep"
PERMS_REVIEWER_DOCS="Read,Glob,Grep,Edit,Write"

# Config overrides (set by load_config if permissions section exists in config.yaml)
CFG_PERMS_DEVELOPER=""
CFG_PERMS_VALIDATOR=""
CFG_PERMS_REVIEWER=""

# ============================================================================
# COLORS & LOGGING (inlined from common.sh)
# ============================================================================

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
MAGENTA='\033[0;35m'
NC='\033[0m'

log_header()  { echo -e "\n${BLUE}════════════════════════════════════════${NC}\n${BLUE}  $1${NC}\n${BLUE}════════════════════════════════════════${NC}"; }
log_subheader() { echo -e "\n${CYAN}─── $1 ───${NC}"; }
log_success() { echo -e "${GREEN}✓ $1${NC}"; }
log_warning() { echo -e "${YELLOW}⚠ $1${NC}"; }
log_error()   { echo -e "${RED}✗ $1${NC}"; }
log_info()    { echo -e "${CYAN}$1${NC}"; }
log_agent()   { echo -e "${MAGENTA}[$1]${NC} $2"; }

# ============================================================================
# UTILITIES (inlined from common.sh)
# ============================================================================

count_ready_items() {
    local file="$1"
    jq '[.items[] | select(.readyForSprint == true and (.passes == false or .passes == null))] | length' "$file" 2>/dev/null || echo 0
}

build_context() {
    local context=""
    for arg in "$@"; do
        [[ -n "$context" ]] && context="$context $arg" || context="$arg"
    done
    local claude_md
    claude_md=$(find_claude_md)
    [[ -n "$claude_md" ]] && context="$context @$claude_md"
    echo "$context"
}

build_completion_contract() {
    cat <<'EOCONTRACT'

## Completion Contract
When you are finished, you MUST write to `.aishore/data/status/result.json`:

On success:
```json
{"status": "pass", "summary": "brief description of what was done"}
```

On failure:
```json
{"status": "fail", "reason": "what went wrong"}
```

This file is how the orchestrator knows you finished. Write it as your final action.
EOCONTRACT
}

acquire_lock() {
    local lockfile="$STATUS_DIR/.aishore.lock"
    mkdir -p "$STATUS_DIR" 2>/dev/null || true
    if ! command -v flock &>/dev/null; then
        log_warning "flock not available — skipping concurrency guard"
        return 0
    fi
    exec 9>"$lockfile"
    if ! flock -n 9; then
        log_error "Another aishore process is running (lockfile: $lockfile)"
        exit 1
    fi
}

append_log() {
    local file="$1" msg="$2"
    mkdir -p "$(dirname "$file")" 2>/dev/null || true
    echo "$msg" >> "$file"
}

verify_checksum() {
    local file="$1"
    local expected="$2"
    [[ -z "$expected" ]] && return 1
    local actual
    if command -v sha256sum &>/dev/null; then
        actual=$(sha256sum "$file" | cut -d' ' -f1)
    elif command -v shasum &>/dev/null; then
        actual=$(shasum -a 256 "$file" | cut -d' ' -f1)
    else
        log_warning "No sha256sum or shasum found — skipping checksum verification"
        return 0
    fi
    [[ "$actual" == "$expected" ]]
}

require_tool() {
    local tool="$1"
    if ! command -v "$tool" &>/dev/null; then
        log_error "'$tool' is required but not installed. Please install it and try again."
        exit 1
    fi
}

# ============================================================================
# AUTO-DETECT CLAUDE.MD
# ============================================================================

find_claude_md() {
    local dir="$PROJECT_ROOT"
    # Check common locations
    for path in "$dir/CLAUDE.md" "$dir/claude.md" "$dir/docs/CLAUDE.md"; do
        [[ -f "$path" ]] && { echo "$path"; return 0; }
    done
    return 0
}

get_claudemd_snippet() {
    cat <<'EOSNIPPET'

## Sprint Orchestration (aishore)

This project uses [aishore](https://github.com/simonweniger/aishore) for AI-assisted sprint management.

### Commands

```bash
# Sprints
.aishore/aishore run [count]        # Run N sprints (default: 1)
.aishore/aishore run FEAT-001       # Run specific item by ID
.aishore/aishore run --auto-commit  # Auto-commit after each sprint

# Grooming
.aishore/aishore groom              # Tech lead: groom bugs
.aishore/aishore groom --backlog    # Product owner: groom features

# Review
.aishore/aishore review             # Architecture review
.aishore/aishore review --update-docs          # Review and update docs
.aishore/aishore review --since <commit>       # Review changes since commit

# Info
.aishore/aishore metrics            # Sprint metrics
.aishore/aishore metrics --json     # Metrics as JSON

# Maintenance
.aishore/aishore update             # Update from upstream (checksum-verified)
.aishore/aishore update --dry-run   # Check for updates without applying
.aishore/aishore checksums          # Regenerate checksums after editing .aishore/ files
.aishore/aishore init               # Interactive setup wizard
```

**Important**: After modifying any files in `.aishore/` (script, agent prompts, etc.), run `.aishore/aishore checksums` before committing. This regenerates `checksums.sha256` which is used to verify integrity during `update`.
EOSNIPPET
}

# ============================================================================
# CONFIGURATION (optional config.yaml, sensible defaults)
# ============================================================================

load_config() {
    # Only load if config exists
    [[ ! -f "$CONFIG_FILE" ]] && { _apply_env_overrides; return 0; }

    if command -v yq &> /dev/null; then
        local cfg_val
        cfg_val=$(yq -r '.validation.command // ""' "$CONFIG_FILE" 2>/dev/null) || cfg_val=""
        [[ -n "$cfg_val" ]] && VALIDATE_CMD="$cfg_val"
        cfg_val=$(yq -r '.validation.timeout // ""' "$CONFIG_FILE" 2>/dev/null) || cfg_val=""
        [[ -n "$cfg_val" ]] && VALIDATE_TIMEOUT="$cfg_val"
        cfg_val=$(yq -r '.models.primary // ""' "$CONFIG_FILE" 2>/dev/null) || cfg_val=""
        [[ -n "$cfg_val" ]] && MODEL_PRIMARY="$cfg_val"
        cfg_val=$(yq -r '.models.fast // ""' "$CONFIG_FILE" 2>/dev/null) || cfg_val=""
        [[ -n "$cfg_val" ]] && MODEL_FAST="$cfg_val"
        cfg_val=$(yq -r '.agent.timeout // ""' "$CONFIG_FILE" 2>/dev/null) || cfg_val=""
        [[ -n "$cfg_val" ]] && AGENT_TIMEOUT="$cfg_val"
        cfg_val=$(yq -r '.notifications.on_complete // ""' "$CONFIG_FILE" 2>/dev/null) || cfg_val=""
        [[ -n "$cfg_val" ]] && NOTIFY_CMD="$cfg_val"
        # Permission overrides
        cfg_val=$(yq -r '.permissions.developer // ""' "$CONFIG_FILE" 2>/dev/null) || cfg_val=""
        [[ -n "$cfg_val" ]] && CFG_PERMS_DEVELOPER="$cfg_val"
        cfg_val=$(yq -r '.permissions.validator // ""' "$CONFIG_FILE" 2>/dev/null) || cfg_val=""
        [[ -n "$cfg_val" ]] && CFG_PERMS_VALIDATOR="$cfg_val"
        cfg_val=$(yq -r '.permissions.reviewer // ""' "$CONFIG_FILE" 2>/dev/null) || cfg_val=""
        [[ -n "$cfg_val" ]] && CFG_PERMS_REVIEWER="$cfg_val"
    else
        # Simple grep fallback for validation command only
        local cfg_cmd
        cfg_cmd=$(grep -E '^\s*command:' "$CONFIG_FILE" 2>/dev/null | head -1 | sed 's/.*command:\s*//' | tr -d '"' || echo "")
        [[ -n "$cfg_cmd" ]] && VALIDATE_CMD="$cfg_cmd"
        # Warn if config.yaml has uncommented model/agent settings that yq would parse
        if grep -qE '^[^#]*(models|agent|permissions):' "$CONFIG_FILE" 2>/dev/null; then
            log_warning "config.yaml has model/timeout settings but yq is not installed — those settings are ignored. Install yq for full config support: https://github.com/mikefarah/yq#install"
        fi
    fi

    # Env vars always win last
    _apply_env_overrides
    return 0
}

_apply_env_overrides() {
    [[ -n "${AISHORE_MODEL_PRIMARY:-}" ]] && MODEL_PRIMARY="$AISHORE_MODEL_PRIMARY"
    [[ -n "${AISHORE_MODEL_FAST:-}" ]] && MODEL_FAST="$AISHORE_MODEL_FAST"
    [[ -n "${AISHORE_AGENT_TIMEOUT:-}" ]] && AGENT_TIMEOUT="$AISHORE_AGENT_TIMEOUT"
    [[ -n "${AISHORE_VALIDATE_CMD:-}" ]] && VALIDATE_CMD="$AISHORE_VALIDATE_CMD"
    [[ -n "${AISHORE_VALIDATE_TIMEOUT:-}" ]] && VALIDATE_TIMEOUT="$AISHORE_VALIDATE_TIMEOUT"
    [[ -n "${AISHORE_NOTIFY_CMD:-}" ]] && NOTIFY_CMD="$AISHORE_NOTIFY_CMD"
    return 0
}

# ============================================================================
# NOTIFICATIONS
# ============================================================================

send_notification() {
    local status="$1"
    local item_id="$2"
    if [[ -n "$NOTIFY_CMD" ]]; then
        if ! bash -c "$NOTIFY_CMD" -- "$status" "$item_id" 2>/dev/null; then
            log_warning "Notification command failed (exit $?) — sprint outcome unaffected"
        fi
    fi
}

# ============================================================================
# ITEM SELECTION
# ============================================================================

pick_item() {
    local specific_id="${1:-}"
    local skip_ids="${2:-}"
    local item_json
    local source_file="$STATUS_DIR/.item_source"

    if [[ -n "$specific_id" ]]; then
        # Pick specific item by ID
        for backlog in "backlog.json" "bugs.json"; do
            item_json=$(jq -r --arg id "$specific_id" '
                .items[] | select(.id == $id) |
                {id, title, description, steps, acceptanceCriteria, priority, status: (.status // "todo"), passes: (.passes // false)}
            ' "$BACKLOG_DIR/$backlog" 2>/dev/null)
            if [[ -n "$item_json" && "$item_json" != "null" ]]; then
                local item_status
                item_status=$(echo "$item_json" | jq -r '.status // "todo"')
                if [[ "$item_status" == "done" ]]; then
                    log_warning "Item $specific_id is already completed — re-running"
                fi
                # Check for unmet dependencies
                local deps_json
                deps_json=$(jq -r --arg id "$specific_id" '
                    .items[] | select(.id == $id) | .dependsOn // empty
                ' "$BACKLOG_DIR/$backlog" 2>/dev/null)
                if [[ -n "$deps_json" && "$deps_json" != "null" ]]; then
                    local all_done_ids="[]"
                    for df in "backlog.json" "bugs.json"; do
                        local df_done
                        df_done=$(jq -r '[.items[] | select(.status == "done") | .id]' "$BACKLOG_DIR/$df" 2>/dev/null || echo "[]")
                        all_done_ids=$(echo "$all_done_ids" "$df_done" | jq -s 'add | unique')
                    done
                    local unmet
                    unmet=$(echo "$deps_json" | jq -r --argjson done "$all_done_ids" '.[] | select(. as $dep | $done | index($dep) == null)' 2>/dev/null)
                    if [[ -n "$unmet" ]]; then
                        log_warning "Item $specific_id has unmet dependencies: $(echo "$unmet" | tr '\n' ', ' | sed 's/,$//')"
                    fi
                fi
                echo "$backlog" > "$source_file"
                echo "$item_json"
                return 0
            fi
        done
        log_error "Item not found: $specific_id — check backlog/backlog.json and backlog/bugs.json for valid item IDs"
        return 1
    fi

    # Build skip list as JSON array for jq
    local skip_json="[]"
    if [[ -n "$skip_ids" ]]; then
        skip_json=$(echo "$skip_ids" | tr ',' '\n' | jq -R . | jq -s .)
    fi

    # Build list of done item IDs from both backlogs for dependency checking
    local done_ids_json="[]"
    for bf in "backlog.json" "bugs.json"; do
        local bf_done
        bf_done=$(jq -r '[.items[] | select(.status == "done") | .id]' "$BACKLOG_DIR/$bf" 2>/dev/null || echo "[]")
        done_ids_json=$(echo "$done_ids_json" "$bf_done" | jq -s 'add | unique')
    done

    # Warn about self-referencing dependencies
    for bf in "backlog.json" "bugs.json"; do
        local self_refs
        self_refs=$(jq -r '.items[] | select(.dependsOn != null) | select(.id as $self | .dependsOn | index($self) != null) | .id' "$BACKLOG_DIR/$bf" 2>/dev/null || true)
        if [[ -n "$self_refs" ]]; then
            while IFS= read -r sid; do
                log_warning "Item $sid has self-referencing dependency — skipping in auto-pick"
            done <<< "$self_refs"
        fi
    done

    # Auto-pick: highest priority ready item (excluding failed items and unmet dependencies)
    for backlog in "backlog.json" "bugs.json"; do
        item_json=$(jq -r --argjson skip "$skip_json" --argjson done_ids "$done_ids_json" '
            [.items[] |
            select(.readyForSprint == true and (.passes == false or .passes == null) and (.status == "todo" or .status == null)) |
            select(.id as $id | $skip | index($id) | not) |
            select(.dependsOn == null or (.dependsOn | length == 0) or (.id as $self | .dependsOn | all(. != $self) and all(. as $dep | $done_ids | index($dep) != null))) |
            . + {_priorityOrder: (if .priority == "must" then 0 elif .priority == "should" then 1 elif .priority == "could" then 2 else 3 end)}] |
            sort_by(._priorityOrder) |
            first |
            if . then {id, title, description, steps, acceptanceCriteria, priority, status: (.status // "todo"), passes: (.passes // false)} else empty end
        ' "$BACKLOG_DIR/$backlog" 2>/dev/null)

        if [[ -n "$item_json" && "$item_json" != "null" ]]; then
            echo "$backlog" > "$source_file"
            echo "$item_json"
            return 0
        fi
    done

    return 1
}

get_item_source() {
    local source_file="$STATUS_DIR/.item_source"
    [[ -f "$source_file" ]] && cat "$source_file" || echo ""
}

# ============================================================================
# SPRINT STATE
# ============================================================================

create_sprint() {
    local item_json="$1"
    local source="$2"
    local item_id
    item_id=$(echo "$item_json" | jq -r '.id')
    local title
    title=$(echo "$item_json" | jq -r '.title // .description')
    local now
    now=$(date -Iseconds)

    local tmp_sprint
    tmp_sprint="$(ensure_tmpdir)/sprint_create.json"
    jq -n \
        --arg sprintId "sprint-$(date +%s)" \
        --arg startedAt "$now" \
        --arg itemId "$item_id" \
        --arg title "$title" \
        --arg source "$source" \
        --argjson steps "$(echo "$item_json" | jq '.steps // []')" \
        --argjson ac "$(echo "$item_json" | jq '.acceptanceCriteria // []')" \
        '{
            sprintId: $sprintId,
            startedAt: $startedAt,
            status: "in_progress",
            item: {
                id: $itemId,
                title: $title,
                sourceBacklog: $source,
                steps: $steps,
                acceptanceCriteria: $ac,
                startedAt: $startedAt
            }
        }' > "$tmp_sprint"
    mv "$tmp_sprint" "$BACKLOG_DIR/sprint.json"

    ITEM_ID="$item_id"
    log_info "Sprint created: $item_id - $title"
}

mark_complete() {
    local item_id="$1"
    local source="$2"
    local attempts="${3:-1}"
    local now
    now=$(date -Iseconds)

    [[ -z "$source" ]] && { log_error "Cannot mark complete: source backlog is empty"; return 1; }

    # Update source backlog
    local tmp
    tmp="$(ensure_tmpdir)/backlog_update.json"
    if jq --arg id "$item_id" --arg ts "$now" '
        (.items[] | select(.id == $id)) |= . + {passes: true, status: "done", readyForSprint: false, completedAt: $ts}
    ' "$BACKLOG_DIR/$source" > "$tmp" 2>/dev/null; then
        mv "$tmp" "$BACKLOG_DIR/$source"
    else
        rm -f "$tmp"
        log_error "Failed to update $source"
        return 1
    fi

    # Update sprint.json
    local tmp_sprint
    tmp_sprint="$(ensure_tmpdir)/sprint_update.json"
    if jq --arg ts "$now" --argjson attempts "$attempts" '.status = "completed" | .completedAt = $ts | .attempts = $attempts | .item.status = "passed" | .item.completedAt = $ts' \
        "$BACKLOG_DIR/sprint.json" > "$tmp_sprint" 2>/dev/null; then
        mv "$tmp_sprint" "$BACKLOG_DIR/sprint.json"
    else
        rm -f "$tmp_sprint"
        log_warning "Failed to update sprint.json status (item already marked complete in $source)"
    fi

    # Append to archive (non-fatal — primary state is already consistent)
    local sprint_id
    sprint_id=$(jq -r '.sprintId' "$BACKLOG_DIR/sprint.json" 2>/dev/null || echo "unknown")
    if ! jq -n --arg date "$(date +%Y-%m-%d)" --arg sid "$sprint_id" --arg iid "$item_id" \
        '{date: $date, sprintId: $sid, itemId: $iid, status: "complete"}' \
        >> "$ARCHIVE_DIR/sprints.jsonl" 2>/dev/null; then
        log_warning "Failed to append to archive — sprint data is still consistent"
    fi
}

reset_sprint() {
    cat > "$BACKLOG_DIR/sprint.json" <<'EOF'
{"sprintId": null, "status": "idle", "item": null}
EOF
}

# ============================================================================
# AGENT EXECUTION
# ============================================================================

# Core process management: launch claude agent and wait for result.json or timeout.
# Args: agent_label model allowed_tools output_format prompt
#   agent_label   - name for logging
#   model         - model to use
#   allowed_tools - comma-separated tool list
#   output_format - "text" or "stream-json" (use "text" for --print capture)
#   prompt        - full prompt string (including context @-files)
# Optional: set AGENT_OUTPUT_FILE before calling to capture --print output to a file.
run_agent_process() {
    local agent_label="$1"
    local model="$2"
    local allowed_tools="$3"
    local output_format="$4"
    local prompt="$5"

    log_agent "$agent_label" "Starting (model: $model, timeout: ${AGENT_TIMEOUT}s)"
    local start_time
    start_time=$(date +%s)

    local has_setsid=false
    if command -v setsid &>/dev/null; then
        has_setsid=true
    fi

    local claude_args=(
        --model "$model"
        --permission-mode acceptEdits
        --allowedTools "$allowed_tools"
    )

    if [[ -n "${AGENT_OUTPUT_FILE:-}" ]]; then
        claude_args+=(--print)
        if [[ "$has_setsid" == true ]]; then
            setsid env -u CLAUDECODE -u CLAUDE_CODE_ENTRYPOINT \
                claude "${claude_args[@]}" \
                -p "$prompt" > "$AGENT_OUTPUT_FILE" 2>&1 &
        else
            env -u CLAUDECODE -u CLAUDE_CODE_ENTRYPOINT \
                claude "${claude_args[@]}" \
                -p "$prompt" > "$AGENT_OUTPUT_FILE" 2>&1 &
        fi
    else
        claude_args+=(--output-format "$output_format")
        if [[ "$has_setsid" == true ]]; then
            setsid env -u CLAUDECODE -u CLAUDE_CODE_ENTRYPOINT \
                claude "${claude_args[@]}" \
                -p "$prompt" &
        else
            env -u CLAUDECODE -u CLAUDE_CODE_ENTRYPOINT \
                claude "${claude_args[@]}" \
                -p "$prompt" &
        fi
    fi

    local agent_pid=$!
    local elapsed=0

    while [[ $elapsed -lt $AGENT_TIMEOUT ]]; do
        if ! kill -0 "$agent_pid" 2>/dev/null; then
            break
        fi
        if [[ -f "$STATUS_DIR/result.json" ]]; then
            sleep 2
            break
        fi
        sleep 5
        elapsed=$((elapsed + 5))
        if [[ $((elapsed % 30)) -eq 0 ]]; then
            log_agent "$agent_label" "Waiting for agent... (${elapsed}s elapsed)"
        fi
    done

    if kill -0 "$agent_pid" 2>/dev/null; then
        log_warning "Agent timed out after ${AGENT_TIMEOUT}s, killing..."
        if [[ "$has_setsid" == true ]]; then
            kill -TERM -- -"$agent_pid" 2>/dev/null || kill -TERM "$agent_pid" 2>/dev/null
            sleep 2
            kill -KILL -- -"$agent_pid" 2>/dev/null || true
        else
            kill -TERM "$agent_pid" 2>/dev/null || true
            sleep 2
            kill -KILL "$agent_pid" 2>/dev/null || true
        fi
    fi

    wait "$agent_pid" 2>/dev/null || true

    local duration
    duration=$(($(date +%s) - start_time))
    log_agent "$agent_label" "Completed in ${duration}s"

    append_log "$LOGS_DIR/agent-runs.log" \
        "$(date -Iseconds)|$agent_label|${AGENT_MODE:-unknown}|${duration}s|$model"
}

build_agent_prompt() {
    local agent_name="$1"
    local mode="$2"

    local prompt_file="$AGENTS_DIR/${agent_name}.md"
    [[ ! -f "$prompt_file" ]] && { log_error "Agent not found: $agent_name"; return 1; }

    local prompt
    prompt="$(cat "$prompt_file")

## Mode
$mode
$(build_completion_contract)"
    echo "$prompt"
}

run_agent() {
    local agent_name="$1"
    local mode="$2"
    local model="${3:-$MODEL_PRIMARY}"
    local context_args="${4:-}"
    local output_file="${5:-}"
    local extra_prompt="${6:-}"

    local prompt_file="$AGENTS_DIR/${agent_name}.md"
    [[ ! -f "$prompt_file" ]] && { log_error "Agent not found: $agent_name"; return 1; }

    rm -f "$STATUS_DIR/result.json"

    local context_files
    if [[ -n "$context_args" ]]; then
        context_files=$(build_context $context_args)
    else
        context_files=$(build_context "@$BACKLOG_DIR/sprint.json")
    fi

    # Derive permissions based on agent role and mode
    local agent_perms
    case "$agent_name" in
        developer)
            agent_perms="${CFG_PERMS_DEVELOPER:-$PERMS_DEVELOPER}" ;;
        validator)
            agent_perms="${CFG_PERMS_VALIDATOR:-$PERMS_VALIDATOR}" ;;
        architect)
            if [[ -n "$output_file" ]]; then
                agent_perms="${CFG_PERMS_REVIEWER:-$PERMS_REVIEWER_DOCS}"
            else
                agent_perms="${CFG_PERMS_REVIEWER:-$PERMS_REVIEWER}"
            fi ;;
        tech-lead|product-owner)
            # Groom agents need full permissions to update backlog files
            agent_perms="${CFG_PERMS_DEVELOPER:-$PERMS_DEVELOPER}" ;;
        *)
            agent_perms="${CFG_PERMS_DEVELOPER:-$PERMS_DEVELOPER}" ;;
    esac

    local prompt
    prompt="$(cat "$prompt_file")
${extra_prompt:+
$extra_prompt}

## Mode
$mode
$(build_completion_contract)"

    if [[ -n "$output_file" ]]; then
        AGENT_OUTPUT_FILE="$output_file" AGENT_MODE="$mode" run_agent_process "$agent_name" "$model" \
            "$agent_perms" "" \
            "$context_files
$prompt"
    else
        AGENT_MODE="$mode" run_agent_process "$agent_name" "$model" \
            "$agent_perms" "text" \
            "$context_files
$prompt"
    fi
}

check_result() {
    if [[ ! -f "$STATUS_DIR/result.json" ]]; then
        log_error "No result file - agent may have crashed. Check .aishore/data/logs/ for details"
        return 1
    fi

    local status
    status=$(jq -r '.status // "unknown"' "$STATUS_DIR/result.json" 2>/dev/null)

    if [[ "$status" == "pass" ]]; then
        local summary
        summary=$(jq -r '.summary // "completed"' "$STATUS_DIR/result.json")
        log_success "$summary"
        return 0
    else
        local reason
        reason=$(jq -r '.reason // "unknown error"' "$STATUS_DIR/result.json")
        log_error "$reason"
        return 1
    fi
}

# ============================================================================
# FAILURE RECOVERY
# ============================================================================

handle_sprint_failure() {
    log_warning "Resetting working tree after sprint failure"
    git checkout -- . 2>/dev/null || true
    git clean -fd 2>/dev/null || true
    reset_sprint
}

# ============================================================================
# COMMANDS
# ============================================================================

print_batch_summary() {
    local batch_start="$1"
    local -n _results=$2
    local -n _items=$3
    local -n _times=$4
    local -n _failed_ids=$5

    local batch_elapsed=$(( $(date +%s) - batch_start ))
    local total=${#_results[@]}
    local total_passed=0
    local total_failed=0

    for r in "${_results[@]}"; do
        if [[ "$r" == "pass" ]]; then
            total_passed=$((total_passed + 1))
        else
            total_failed=$((total_failed + 1))
        fi
    done

    echo ""
    log_header "Batch Summary"
    printf "  %-8s %-12s %-8s %s\n" "Sprint" "Item" "Status" "Elapsed"
    printf "  %-8s %-12s %-8s %s\n" "------" "----" "------" "-------"

    for ((idx=0; idx<total; idx++)); do
        local status_display
        if [[ "${_results[$idx]}" == "pass" ]]; then
            status_display="${GREEN}pass${NC}"
        else
            status_display="${RED}fail${NC}"
        fi
        local mins=$(( _times[idx] / 60 ))
        local secs=$(( _times[idx] % 60 ))
        printf "  %-8s %-12s " "$((idx + 1))" "${_items[$idx]}"
        echo -e "${status_display}     ${mins}m${secs}s"
    done

    printf "  %-8s %-12s %-8s %s\n" "------" "----" "------" "-------"
    local total_mins=$(( batch_elapsed / 60 ))
    local total_secs=$(( batch_elapsed % 60 ))
    printf "  Passed: %d  Failed: %d  Total: %dm%ds\n" "$total_passed" "$total_failed" "$total_mins" "$total_secs"

    if [[ $total_failed -gt 0 ]]; then
        echo ""
        echo "  Failed items:"
        for fid in "${!_failed_ids[@]}"; do
            echo "    - $fid: ${_failed_ids[$fid]}"
        done
    fi
    echo ""
}

cmd_run() {
    require_tool jq
    require_tool git

    local count=1
    local auto_commit=false
    local dry_run=false
    local specific_id=""
    local retries=0

    while [[ $# -gt 0 ]]; do
        case "$1" in
            --dry-run) dry_run=true; shift ;;
            --auto-commit) auto_commit=true; shift ;;
            --retries)
                shift
                if [[ $# -eq 0 || ! "$1" =~ ^[0-9]+$ ]]; then
                    log_error "--retries requires a numeric argument"
                    return 1
                fi
                retries="$1"
                shift ;;
            *)
                if [[ "$1" =~ ^[0-9]+$ ]]; then
                    count="$1"
                else
                    # Assume it's an item ID (e.g., TEST-006, FEAT-001)
                    specific_id="$1"
                    count=1
                fi
                shift ;;
        esac
    done

    # --dry-run and --auto-commit are mutually exclusive
    if [[ "$dry_run" == "true" && "$auto_commit" == "true" ]]; then
        log_error "--dry-run and --auto-commit cannot be used together"
        return 1
    fi

    # Dry-run mode: show what would happen without modifying anything
    if [[ "$dry_run" == "true" ]]; then
        load_config
        cd "$PROJECT_ROOT"

        log_header "aishore - Dry Run"
        echo "Project: $PROJECT_ROOT"
        echo ""

        # Pick item (writes .item_source but that's a runtime file in .gitignore)
        local item_json
        if ! item_json=$(pick_item "$specific_id" ""); then
            if [[ -n "$specific_id" ]]; then
                log_error "Item not found: $specific_id — check backlog/backlog.json and backlog/bugs.json for valid item IDs"
            else
                log_warning "No ready items in backlog. Run '.aishore/aishore groom' to prepare items, or set readyForSprint: true in backlog/backlog.json"
            fi
            return 1
        fi

        local item_id item_title
        item_id=$(echo "$item_json" | jq -r '.id')
        item_title=$(echo "$item_json" | jq -r '.title // .description')

        # Display selected item
        log_subheader "Selected Item"
        echo "$item_json" | jq .
        echo ""

        # Display developer prompt
        log_subheader "Developer Prompt"
        build_agent_prompt "developer" "implement"
        echo ""

        # Display validation command
        log_subheader "Validation Command"
        if [[ -n "$VALIDATE_CMD" ]]; then
            echo "$VALIDATE_CMD"
        else
            echo "none configured"
        fi
        echo ""

        # Summary
        log_header "Dry run complete"
        echo "Would pick: $item_id ($item_title)"
        echo "Model: $MODEL_PRIMARY"
        echo "Validation: ${VALIDATE_CMD:-none}"
        return 0
    fi

    acquire_lock
    load_config
    cd "$PROJECT_ROOT"

    # Stash pre-existing uncommitted changes so sprints don't destroy them
    local did_stash=false
    if ! git diff --quiet 2>/dev/null || ! git diff --cached --quiet 2>/dev/null || [[ -n "$(git ls-files --others --exclude-standard 2>/dev/null)" ]]; then
        log_warning "Stashing pre-existing uncommitted changes"
        git stash push -u -m "aishore: pre-sprint stash" >/dev/null 2>&1
        did_stash=true
        AISHORE_DID_STASH=true
    fi

    log_header "aishore - Sprint Runner"
    echo "Project: $PROJECT_ROOT"
    if [[ -n "$specific_id" ]]; then
        echo "Item: $specific_id"
    else
        echo "Sprints: $count"
    fi
    [[ "$auto_commit" == "true" ]] && echo "Auto-commit: enabled"
    [[ "$retries" -gt 0 ]] && echo "Retries: $retries"
    echo ""

    local passed=0 failed=0
    declare -A FAILED_IDS
    local batch_start
    batch_start=$(date +%s)
    local sprint_results=()
    local sprint_items=()
    local sprint_times=()

    for ((i=1; i<=count; i++)); do
        [[ $count -gt 1 ]] && log_subheader "Sprint $i/$count"
        local sprint_start
        sprint_start=$(date +%s)

        # Build comma-separated exclusion list from failed items
        local skip_list=""
        for fid in "${!FAILED_IDS[@]}"; do
            [[ -n "$skip_list" ]] && skip_list="$skip_list,$fid" || skip_list="$fid"
        done

        local item_json
        if ! item_json=$(pick_item "$specific_id" "$skip_list"); then
            if [[ -n "$specific_id" ]]; then
                log_error "Item not found: $specific_id — check backlog/backlog.json and backlog/bugs.json for valid item IDs"
            else
                log_warning "No ready items in backlog. Run '.aishore/aishore groom' to prepare items, or set readyForSprint: true in backlog/backlog.json"
            fi
            break
        fi

        local item_source
        item_source=$(get_item_source)
        [[ -z "$item_source" ]] && { log_error "Failed to determine item source. Ensure the item exists in backlog/backlog.json or backlog/bugs.json and retry"; break; }

        create_sprint "$item_json" "$item_source"

        # Run developer and validation with retry loop
        local attempt=0
        local sprint_passed=false
        local retry_extra_prompt=""

        for ((attempt=0; attempt<=retries; attempt++)); do
            if [[ $attempt -gt 0 ]]; then
                log_info "Retry attempt $attempt/$retries"
            fi

            # Run developer agent
            run_agent "developer" "implement" "$MODEL_PRIMARY" "" "" "$retry_extra_prompt"
            if ! check_result; then
                log_error "Implementation failed"
                if [[ $attempt -lt $retries ]]; then
                    local fail_reason=""
                    if [[ -f "$STATUS_DIR/result.json" ]]; then
                        fail_reason=$(jq -r '.reason // "unknown error"' "$STATUS_DIR/result.json" 2>/dev/null)
                    fi
                    retry_extra_prompt="Previous attempt failed during implementation. Failure reason: ${fail_reason}. Fix the issues and ensure all acceptance criteria pass."
                    log_info "Will retry with failure context"
                    continue
                fi
                failed=$((failed + 1))
                FAILED_IDS["$ITEM_ID"]="Implementation failed"
                sprint_results+=("fail")
                sprint_items+=("$ITEM_ID")
                sprint_times+=("$(( $(date +%s) - sprint_start ))")
                send_notification "fail" "$ITEM_ID"
                handle_sprint_failure
                break
            fi

            # Run validation command (if configured)
            local validate_failed=false
            local validate_output=""
            if [[ -n "$VALIDATE_CMD" ]]; then
                log_info "Running validation: $VALIDATE_CMD"
                local validate_ok=true
                local validate_tmpfile
                validate_tmpfile="$(ensure_tmpdir)/validate_output.txt"
                if command -v timeout &>/dev/null; then
                    if ! timeout "$VALIDATE_TIMEOUT" bash -c "$VALIDATE_CMD" >"$validate_tmpfile" 2>&1; then
                        validate_ok=false
                    fi
                else
                    if ! bash -c "$VALIDATE_CMD" >"$validate_tmpfile" 2>&1; then
                        validate_ok=false
                    fi
                fi
                validate_output=$(cat "$validate_tmpfile" 2>/dev/null || true)
                rm -f "$validate_tmpfile"
                if [[ "$validate_ok" != "true" ]]; then
                    log_error "Validation command failed"
                    validate_failed=true
                else
                    log_success "Validation passed"
                fi
            fi

            if [[ "$validate_failed" == "true" ]]; then
                if [[ $attempt -lt $retries ]]; then
                    retry_extra_prompt="Previous attempt failed validation command ($VALIDATE_CMD). Validation output:
${validate_output}
Fix the issues and ensure all acceptance criteria pass."
                    log_info "Will retry with failure context"
                    continue
                fi
                failed=$((failed + 1))
                FAILED_IDS["$ITEM_ID"]="Validation failed"
                sprint_results+=("fail")
                sprint_items+=("$ITEM_ID")
                sprint_times+=("$(( $(date +%s) - sprint_start ))")
                send_notification "fail" "$ITEM_ID"
                handle_sprint_failure
                break
            fi

            # Run validator agent
            run_agent "validator" "validate" "$MODEL_FAST"
            if ! check_result; then
                log_error "Validation failed"
                if [[ $attempt -lt $retries ]]; then
                    local agent_fail_reason=""
                    if [[ -f "$STATUS_DIR/result.json" ]]; then
                        agent_fail_reason=$(jq -r '.reason // "unknown error"' "$STATUS_DIR/result.json" 2>/dev/null)
                    fi
                    retry_extra_prompt="Previous attempt failed validator agent review. Failure reason: ${agent_fail_reason}."
                    if [[ -n "$validate_output" ]]; then
                        retry_extra_prompt="${retry_extra_prompt} Validation command output: ${validate_output}."
                    fi
                    retry_extra_prompt="${retry_extra_prompt} Fix the issues and ensure all acceptance criteria pass."
                    log_info "Will retry with failure context"
                    continue
                fi
                failed=$((failed + 1))
                FAILED_IDS["$ITEM_ID"]="Validator failed"
                sprint_results+=("fail")
                sprint_items+=("$ITEM_ID")
                sprint_times+=("$(( $(date +%s) - sprint_start ))")
                send_notification "fail" "$ITEM_ID"
                handle_sprint_failure
                break
            fi

            # All validations passed
            sprint_passed=true
            break
        done

        # Track total attempts for archiving
        local total_attempts=$((attempt + 1))

        [[ "$sprint_passed" != "true" ]] && continue

        # Success
        if mark_complete "$ITEM_ID" "$item_source" "$total_attempts"; then
            log_success "Sprint complete: $ITEM_ID"
            passed=$((passed + 1))
            sprint_results+=("pass")
            sprint_items+=("$ITEM_ID")
            sprint_times+=("$(( $(date +%s) - sprint_start ))")
            send_notification "pass" "$ITEM_ID"
        else
            log_error "Failed to mark $ITEM_ID complete"
            failed=$((failed + 1))
            FAILED_IDS["$ITEM_ID"]="Archival failed"
            sprint_results+=("fail")
            sprint_items+=("$ITEM_ID")
            sprint_times+=("$(( $(date +%s) - sprint_start ))")
            send_notification "fail" "$ITEM_ID"
            continue
        fi

        # Handle commits
        if [[ "$auto_commit" == "true" ]]; then
            git add -A && git diff --cached --quiet || \
                git commit -m "feat($ITEM_ID): implement sprint item

Co-Authored-By: Claude <noreply@anthropic.com>"
        elif [[ $count -eq 1 ]]; then
            echo ""
            git status --short
            read -r -p "Commit? [y/N] " c
            if [[ $c == [yY] ]]; then
                git add -A && git commit -m "feat($ITEM_ID): implement sprint item

Co-Authored-By: Claude <noreply@anthropic.com>"
            fi
        fi
    done

    # Print batch summary for multi-sprint runs
    if [[ $count -gt 1 ]]; then
        print_batch_summary "$batch_start" sprint_results sprint_items sprint_times FAILED_IDS
    fi

    # Restore pre-existing uncommitted changes
    if [[ "$did_stash" == "true" ]]; then
        log_info "Restoring pre-existing uncommitted changes"
        AISHORE_DID_STASH=""
        git stash pop >/dev/null 2>&1 || log_warning "Failed to restore stashed changes — run 'git stash pop' manually"
    fi

    log_header "Results: $passed passed, $failed failed"
    [[ $failed -gt 0 || $passed -eq 0 ]] && exit 1 || exit 0
}

cmd_groom() {
    require_tool jq

    local mode="bugs"
    [[ "${1:-}" == "--backlog" ]] && mode="backlog"

    acquire_lock
    load_config
    cd "$PROJECT_ROOT"

    local agent
    if [[ "$mode" == "backlog" ]]; then
        log_header "Product Owner: Backlog Grooming"
        agent="product-owner"
    else
        log_header "Tech Lead: Bugs/Tech Debt Grooming"
        agent="tech-lead"
    fi

    local ready_backlog
    ready_backlog=$(count_ready_items "$BACKLOG_DIR/backlog.json")
    local ready_bugs
    ready_bugs=$(count_ready_items "$BACKLOG_DIR/bugs.json")
    log_info "Current ready buffer: $((ready_backlog + ready_bugs)) items ($ready_backlog features, $ready_bugs bugs)"
    echo ""

    local context_args="@$BACKLOG_DIR/backlog.json @$BACKLOG_DIR/bugs.json"
    [[ -f "$ARCHIVE_DIR/sprints.jsonl" ]] && context_args="$context_args @$ARCHIVE_DIR/sprints.jsonl"

    log_info "Running $agent agent..."

    run_agent "$agent" "groom" "$MODEL_FAST" "$context_args"

    if ! check_result; then
        exit 1
    fi
}

cmd_review() {
    require_tool jq

    local update_docs=false
    local since=""

    while [[ $# -gt 0 ]]; do
        case "$1" in
            --update-docs) update_docs=true; shift ;;
            --since) since="$2"; shift 2 ;;
            *) shift ;;
        esac
    done

    acquire_lock
    load_config
    cd "$PROJECT_ROOT"

    log_header "Architecture Review"
    echo "Mode: $([[ "$update_docs" == "true" ]] && echo "Update docs" || echo "Read-only")"
    echo ""

    local context_args="@$BACKLOG_DIR/backlog.json @$BACKLOG_DIR/bugs.json"
    [[ -f "$ARCHIVE_DIR/sprints.jsonl" ]] && context_args="$context_args @$ARCHIVE_DIR/sprints.jsonl"

    local extra_prompt
    extra_prompt="## Additional Context
$([[ -n "$since" ]] && echo "Review changes since commit: $since")
$([[ "$update_docs" == "true" ]] && echo "You may update documentation and add backlog items." || echo "Read-only review. Do not modify files.")"

    local output_file
    output_file="$(ensure_tmpdir)/review_output.txt"

    log_info "Running architect agent..."

    run_agent "architect" "review" "$MODEL_PRIMARY" "$context_args" "$output_file" "$extra_prompt"

    # Save review output to persistent log
    local review_log
    review_log="$DATA_DIR/logs/review-$(date +%Y%m%dT%H%M%S).md"
    if [[ -s "$output_file" ]]; then
        cp "$output_file" "$review_log"
        log_info "Review output saved to: $review_log"
    fi

    # Print the review output
    if [[ -s "$output_file" ]]; then
        echo ""
        echo "═══════════════════════════════════════════"
        echo "  ARCHITECTURE REVIEW OUTPUT"
        echo "═══════════════════════════════════════════"
        echo ""
        cat "$output_file"
        echo ""
    fi

    if ! check_result; then
        exit 1
    fi
}

cmd_metrics() {
    require_tool jq

    local json_output=false
    [[ "${1:-}" == "--json" ]] && json_output=true

    load_config

    local sprints_file="$ARCHIVE_DIR/sprints.jsonl"
    local backlog_file="$BACKLOG_DIR/backlog.json"
    local bugs_file="$BACKLOG_DIR/bugs.json"

    local ready_backlog
    ready_backlog=$(count_ready_items "$backlog_file")
    local ready_bugs
    ready_bugs=$(count_ready_items "$bugs_file")

    if [[ "$json_output" == "true" ]]; then
        local completed
        completed=$([[ -f "$sprints_file" ]] && wc -l < "$sprints_file" | tr -d ' ' || echo 0)
        local backlog_total
        backlog_total=$(jq '.items | length' "$backlog_file" 2>/dev/null || echo 0)
        local bugs_total
        bugs_total=$(jq '.items | length' "$bugs_file" 2>/dev/null || echo 0)

        cat <<EOF
{
  "timestamp": "$(date -Iseconds)",
  "sprints": {"completed": $completed},
  "backlog": {"total": $backlog_total, "ready": $ready_backlog},
  "bugs": {"total": $bugs_total, "ready": $ready_bugs}
}
EOF
    else
        log_header "aishore Metrics"
        echo ""
        echo "Completed Sprints: $([[ -f "$sprints_file" ]] && wc -l < "$sprints_file" | tr -d ' ' || echo 0)"
        echo ""
        echo "Backlog:"
        echo "  Total items: $(jq '.items | length' "$backlog_file" 2>/dev/null || echo 0)"
        echo "  Ready for sprint: $ready_backlog"
        echo ""
        echo "Bugs/Tech Debt:"
        echo "  Total items: $(jq '.items | length' "$bugs_file" 2>/dev/null || echo 0)"
        echo "  Ready for sprint: $ready_bugs"
    fi
}

cmd_status() {
    require_tool jq

    local backlog_file="$BACKLOG_DIR/backlog.json"
    local bugs_file="$BACKLOG_DIR/bugs.json"
    local sprints_file="$ARCHIVE_DIR/sprints.jsonl"

    log_header "Backlog Status"
    echo ""

    # --- Item counts by status ---
    if [[ -f "$backlog_file" ]]; then
        local feat_todo feat_in_progress feat_done
        feat_todo=$(jq '[.items[] | select((.status // "todo") == "todo")] | length' "$backlog_file" 2>/dev/null || echo 0)
        feat_in_progress=$(jq '[.items[] | select((.status // "todo") == "in-progress")] | length' "$backlog_file" 2>/dev/null || echo 0)
        feat_done=$(jq '[.items[] | select((.status // "todo") == "done")] | length' "$backlog_file" 2>/dev/null || echo 0)
        echo "Features: $feat_todo todo, $feat_in_progress in-progress, $feat_done done"
    else
        log_warning "Backlog is empty"
    fi

    if [[ -f "$bugs_file" ]]; then
        local bug_todo bug_in_progress bug_done
        bug_todo=$(jq '[.items[] | select((.status // "todo") == "todo")] | length' "$bugs_file" 2>/dev/null || echo 0)
        bug_in_progress=$(jq '[.items[] | select((.status // "todo") == "in-progress")] | length' "$bugs_file" 2>/dev/null || echo 0)
        bug_done=$(jq '[.items[] | select((.status // "todo") == "done")] | length' "$bugs_file" 2>/dev/null || echo 0)
        echo "Bugs: $bug_todo todo, $bug_in_progress in-progress, $bug_done done"
    fi

    # --- Ready for sprint ---
    echo ""
    log_subheader "Ready for sprint"
    local has_ready=false

    if [[ -f "$backlog_file" ]]; then
        local ready_items
        ready_items=$(jq -r '.items[] | select(.readyForSprint == true) | "  \(.id): \(.title)"' "$backlog_file" 2>/dev/null)
        if [[ -n "$ready_items" ]]; then
            echo "$ready_items"
            has_ready=true
        fi
    fi

    if [[ -f "$bugs_file" ]]; then
        local ready_bugs
        ready_bugs=$(jq -r '.items[] | select(.readyForSprint == true) | "  \(.id): \(.title)"' "$bugs_file" 2>/dev/null)
        if [[ -n "$ready_bugs" ]]; then
            echo "$ready_bugs"
            has_ready=true
        fi
    fi

    if [[ "$has_ready" == "false" ]]; then
        log_warning "No items ready for sprint — run groom or set readyForSprint: true"
    fi

    # --- Recent sprints ---
    echo ""
    log_subheader "Recent sprints"
    if [[ -f "$sprints_file" ]]; then
        tail -5 "$sprints_file" | while IFS= read -r line; do
            echo "  $(echo "$line" | jq -r '"\(.date) \(.itemId) \(.status)"')"
        done
    else
        log_info "No sprints run yet"
    fi

    # --- Warnings ---
    if [[ ! -f "$backlog_file" ]] && [[ ! -f "$bugs_file" ]]; then
        echo ""
        log_warning "Backlog is empty"
    fi

    local all_done=true
    if [[ -f "$backlog_file" ]]; then
        local not_done
        not_done=$(jq '[.items[] | select((.status // "todo") != "done")] | length' "$backlog_file" 2>/dev/null || echo 0)
        [[ "$not_done" -gt 0 ]] && all_done=false
    fi
    if [[ -f "$bugs_file" ]] && [[ "$all_done" == "true" ]]; then
        local not_done_bugs
        not_done_bugs=$(jq '[.items[] | select((.status // "todo") != "done")] | length' "$bugs_file" 2>/dev/null || echo 0)
        [[ "$not_done_bugs" -gt 0 ]] && all_done=false
    fi
    if [[ "$all_done" == "true" ]] && { [[ -f "$backlog_file" ]] || [[ -f "$bugs_file" ]]; }; then
        echo ""
        log_info "All items completed"
    fi
}

cmd_init() {
    log_header "aishore setup wizard"
    echo ""
    echo "  This will walk you through setting up aishore for your project."
    echo "  Press Enter to accept defaults shown in [brackets]."
    echo ""

    local reinit=false
    if [[ -f "$BACKLOG_DIR/backlog.json" ]]; then
        log_warning "aishore already initialized (backlog.json exists)"
        read -r -p "  Reinitialize? This preserves existing backlogs. [y/N] " c
        [[ $c != [yY] ]] && exit 0
        reinit=true
        echo ""
    fi

    # ── Step 1: Prerequisites ──────────────────────────────────────────
    log_subheader "Step 1/6 — Prerequisites"

    # Check git
    if git -C "$PROJECT_ROOT" rev-parse --is-inside-work-tree &>/dev/null; then
        log_success "Git repository detected"
    else
        log_error "Not a git repository"
        echo "  aishore tracks work via git commits. Please initialize git first:"
        echo "    git init && git add -A && git commit -m 'initial commit'"
        exit 1
    fi

    # Check Claude CLI
    if command -v claude &>/dev/null; then
        log_success "Claude CLI found ($(claude --version 2>/dev/null || echo 'installed'))"
    else
        log_error "Claude CLI not found"
        echo "  Install it: https://docs.anthropic.com/en/docs/claude-code"
        exit 1
    fi

    # Check jq (used for backlog manipulation)
    if command -v jq &>/dev/null; then
        log_success "jq found"
    else
        log_warning "jq not found — some features may be limited"
        echo "  Recommended: install jq (https://jqlang.github.io/jq/)"
    fi

    echo ""

    # ── Step 2: Project info ───────────────────────────────────────────
    log_subheader "Step 2/6 — Project"

    # Detect project name from package.json, Cargo.toml, or directory
    local detected_name=""
    if [[ -f "$PROJECT_ROOT/package.json" ]] && command -v jq &>/dev/null; then
        detected_name=$(jq -r '.name // empty' "$PROJECT_ROOT/package.json" 2>/dev/null || true)
    fi
    if [[ -z "$detected_name" && -f "$PROJECT_ROOT/Cargo.toml" ]]; then
        detected_name=$(grep -m1 '^name' "$PROJECT_ROOT/Cargo.toml" 2>/dev/null | sed 's/.*= *"\(.*\)"/\1/' || true)
    fi
    [[ -z "$detected_name" ]] && detected_name=$(basename "$PROJECT_ROOT")

    read -r -p "  Project name [$detected_name]: " project_name
    project_name="${project_name:-$detected_name}"

    echo ""

    # ── Step 3: Validation command ─────────────────────────────────────
    log_subheader "Step 3/6 — Validation"
    echo "  After each sprint, aishore runs a command to verify the code works."
    echo "  Examples: 'npm run build', 'cargo test', 'make check'"
    echo ""

    # Detect likely validation command
    local detected_validate=""
    if [[ -f "$PROJECT_ROOT/package.json" ]]; then
        if command -v jq &>/dev/null; then
            local has_test has_build has_check
            has_test=$(jq -r '.scripts.test // empty' "$PROJECT_ROOT/package.json" 2>/dev/null || true)
            has_build=$(jq -r '.scripts.build // empty' "$PROJECT_ROOT/package.json" 2>/dev/null || true)
            has_check=$(jq -r '.scripts.check // empty' "$PROJECT_ROOT/package.json" 2>/dev/null || true)
            if [[ -n "$has_check" ]]; then
                detected_validate="npm run check"
            elif [[ -n "$has_build" && -n "$has_test" ]]; then
                detected_validate="npm run build && npm test"
            elif [[ -n "$has_build" ]]; then
                detected_validate="npm run build"
            elif [[ -n "$has_test" ]]; then
                detected_validate="npm test"
            fi
        fi
    elif [[ -f "$PROJECT_ROOT/Cargo.toml" ]]; then
        detected_validate="cargo test"
    elif [[ -f "$PROJECT_ROOT/Makefile" ]]; then
        detected_validate="make test"
    elif [[ -f "$PROJECT_ROOT/pyproject.toml" || -f "$PROJECT_ROOT/setup.py" ]]; then
        detected_validate="python -m pytest"
    elif [[ -f "$PROJECT_ROOT/go.mod" ]]; then
        detected_validate="go test ./..."
    fi

    if [[ -n "$detected_validate" ]]; then
        read -r -p "  Validation command [$detected_validate]: " validate_cmd
        validate_cmd="${validate_cmd:-$detected_validate}"
    else
        read -r -p "  Validation command (or leave empty to skip): " validate_cmd
    fi

    echo ""

    # ── Step 4: Product requirements ───────────────────────────────────
    log_subheader "Step 4/6 — Product requirements"
    echo "  aishore works best when agents have context about what you're building."
    echo ""

    # Check for existing requirements docs
    local prd_found=""
    for candidate in \
        "$PROJECT_ROOT/product.md" "$PROJECT_ROOT/PRODUCT.md" \
        "$PROJECT_ROOT/prd.md" "$PROJECT_ROOT/PRD.md" \
        "$PROJECT_ROOT/docs/product.md" "$PROJECT_ROOT/docs/PRD.md" \
        "$PROJECT_ROOT/docs/WEBSITE_BRIEF.md" \
        "$PROJECT_ROOT/README.md"; do
        if [[ -f "$candidate" ]]; then
            prd_found="$candidate"
            break
        fi
    done

    local claude_md
    claude_md=$(find_claude_md)

    if [[ -n "$claude_md" ]]; then
        log_success "Found $claude_md — agents will use this automatically"
    else
        log_info "No CLAUDE.md found — will create one during scaffolding"
    fi

    if [[ -n "$prd_found" ]]; then
        log_success "Found requirements doc: $prd_found"
    else
        log_info "No product requirements doc found (product.md, prd.md, etc.)"
        echo "  Tip: a product.md helps the product-owner agent prioritize features."
        echo "  Even a short description of what you're building is useful."
    fi

    echo ""

    # ── Step 5: Create files ───────────────────────────────────────────
    log_subheader "Step 5/6 — Scaffolding"

    # Create directories
    mkdir -p "$STATUS_DIR" "$LOGS_DIR" "$ARCHIVE_DIR" "$AGENTS_DIR"
    log_success "Created directory structure"

    # Write config.yaml
    if [[ ! -f "$CONFIG_FILE" || "$reinit" == true ]]; then
        cat > "$CONFIG_FILE" << EOF
# aishore configuration

project:
  name: "$project_name"

validation:
  command: "$validate_cmd"
  timeout: 120

# models:
#   primary: "claude-opus-4-6"
#   fast: "claude-sonnet-4-6"

# agent:
#   timeout: 3600

# notifications:
#   on_complete: "notify-send 'aishore' \"Sprint \$1: \$2\""
#   # Examples:
#   #   Linux:  notify-send 'aishore' "Sprint \$1: \$2"
#   #   macOS:  osascript -e "display notification \"Sprint \$1: \$2\" with title \"aishore\""
#   #   Webhook: curl -s -X POST https://example.com/hook -d "{\"status\":\"\$1\",\"item\":\"\$2\"}"
EOF
        log_success "Wrote .aishore/config.yaml"
    else
        log_info "Kept existing .aishore/config.yaml"
    fi

    # Create backlogs (never overwrite existing)
    if [[ ! -f "$BACKLOG_DIR/backlog.json" ]]; then
        cat > "$BACKLOG_DIR/backlog.json" << 'EOF'
{
  "description": "Feature backlog",
  "items": [],
  "_dependsOn_docs": "Items may include an optional 'dependsOn' array of item ID strings (e.g. \"dependsOn\": [\"FEAT-001\"]). Auto-pick skips items whose dependencies are not yet done."
}
EOF
        log_success "Created backlog/backlog.json"
    else
        log_info "Kept existing backlog/backlog.json ($(jq '.items | length' "$BACKLOG_DIR/backlog.json" 2>/dev/null || echo '?') items)"
    fi

    if [[ ! -f "$BACKLOG_DIR/bugs.json" ]]; then
        cat > "$BACKLOG_DIR/bugs.json" << 'EOF'
{
  "description": "Bugs and tech debt",
  "items": []
}
EOF
        log_success "Created backlog/bugs.json"
    else
        log_info "Kept existing backlog/bugs.json"
    fi

    if [[ ! -f "$BACKLOG_DIR/sprint.json" ]]; then
        echo '{"sprintId": null, "status": "idle", "item": null}' > "$BACKLOG_DIR/sprint.json"
        log_success "Created backlog/sprint.json"
    else
        log_info "Kept existing backlog/sprint.json"
    fi

    touch "$ARCHIVE_DIR/sprints.jsonl"

    # Update .gitignore
    local gitignore="$PROJECT_ROOT/.gitignore"
    local entries_file="$AISHORE_ROOT/gitignore-entries.txt"
    local gitignore_content=""
    if [[ -f "$entries_file" ]]; then
        # Read entries from file, stripping comment lines and blank lines
        gitignore_content=$(grep -v '^#' "$entries_file" | grep -v '^$' || true)
    else
        # Fallback to hardcoded entries
        gitignore_content=".aishore/data/logs/
.aishore/data/status/result.json
.aishore/data/status/.item_source
.aishore/data/status/.aishore.lock"
    fi
    if [[ -f "$gitignore" ]]; then
        if ! grep -q ".aishore/data/logs/" "$gitignore" 2>/dev/null; then
            printf '\n# aishore runtime files\n%s\n' "$gitignore_content" >> "$gitignore"
            log_success "Updated .gitignore"
        else
            log_info ".gitignore already configured"
        fi
    else
        printf '# aishore runtime files\n%s\n' "$gitignore_content" > "$gitignore"
        log_success "Created .gitignore"
    fi

    # Add aishore section to CLAUDE.md
    local snippet
    snippet=$(get_claudemd_snippet)
    if [[ -n "$claude_md" ]]; then
        if grep -q "## Sprint Orchestration (aishore)" "$claude_md" 2>/dev/null; then
            log_info "CLAUDE.md already contains aishore section"
        else
            printf '%s\n' "$snippet" >> "$claude_md"
            log_success "Appended aishore section to CLAUDE.md"
        fi
    else
        claude_md="$PROJECT_ROOT/CLAUDE.md"
        printf '# %s\n%s\n' "$project_name" "$snippet" > "$claude_md"
        log_success "Created CLAUDE.md with aishore section"
    fi

    echo ""

    # ── Step 6: Summary & next steps ───────────────────────────────────
    log_subheader "Step 6/6 — Ready"
    echo ""
    log_success "aishore initialized for $project_name"
    echo ""

    # Status summary
    echo "  Project:      $project_name"
    echo "  Validation:   ${validate_cmd:-<none>}"
    echo "  CLAUDE.md:    ${claude_md:-<not found>}"
    echo "  Requirements: ${prd_found:-<not found>}"
    echo ""

    # Contextual next steps based on what's missing
    echo -e "${CYAN}Next steps:${NC}"
    local step=1

    local item_count=0
    if command -v jq &>/dev/null && [[ -f "$BACKLOG_DIR/backlog.json" ]]; then
        item_count=$(jq '.items | length' "$BACKLOG_DIR/backlog.json" 2>/dev/null || echo 0)
    fi

    if [[ "$item_count" -eq 0 ]]; then
        echo "  $step. Add features to backlog/backlog.json (or run: .aishore/aishore groom --backlog)"
        step=$((step + 1))
        echo "  $step. Groom items for sprint readiness: .aishore/aishore groom"
        step=$((step + 1))
    fi

    echo "  $step. Run your first sprint: .aishore/aishore run"
    echo ""
}

cmd_version() {
    echo "aishore version $AISHORE_VERSION"
}

cmd_update() {
    local repo_url="https://raw.githubusercontent.com/simonplant/aishore/main"
    local dry_run=false
    local force=false
    local no_verify=false

    while [[ $# -gt 0 ]]; do
        case "$1" in
            --dry-run|--check) dry_run=true; shift ;;
            --force) force=true; shift ;;
            --no-verify) no_verify=true; shift ;;
            *) shift ;;
        esac
    done

    if [[ "$no_verify" == "true" && "$force" != "true" ]]; then
        log_error "--no-verify requires --force"
        exit 1
    fi

    log_header "aishore Update"
    echo "Current version: $AISHORE_VERSION"
    echo ""

    # Check for curl or wget
    local fetch_cmd=""
    if command -v curl &> /dev/null; then
        fetch_cmd="curl -fsSL"
    elif command -v wget &> /dev/null; then
        fetch_cmd="wget -qO-"
    else
        log_error "curl or wget required for update"
        exit 1
    fi

    # Fetch remote version from VERSION file
    log_info "Checking for updates..."
    local remote_version
    remote_version=$($fetch_cmd "$repo_url/VERSION" 2>/dev/null | tr -d '[:space:]') || {
        log_error "Failed to fetch remote version from $repo_url/VERSION"
        exit 1
    }

    if [[ -z "$remote_version" ]]; then
        log_error "Could not determine remote version"
        exit 1
    fi

    echo "Remote version: $remote_version"
    echo ""

    if [[ "$AISHORE_VERSION" == "$remote_version" ]] && [[ "$force" != "true" ]]; then
        log_success "Already up to date"
        return 0
    fi

    # Show what will be updated
    echo "Files to update:"
    echo "  .aishore/aishore"
    echo "  .aishore/gitignore-entries.txt"
    echo "  .aishore/agents/developer.md"
    echo "  .aishore/agents/validator.md"
    echo "  .aishore/agents/tech-lead.md"
    echo "  .aishore/agents/product-owner.md"
    echo "  .aishore/agents/architect.md"
    echo ""
    echo "Not modified (your content):"
    echo "  .aishore/config.yaml"
    echo "  backlog/*"
    echo ""

    if [[ "$dry_run" == "true" ]]; then
        log_info "Dry run - no changes made"
        echo ""
        echo "To apply update:"
        echo "  .aishore/aishore update"
        return 0
    fi

    # Fetch checksums manifest
    log_info "Fetching checksums..."
    local checksums_content=""
    checksums_content=$($fetch_cmd "$repo_url/.aishore/checksums.sha256" 2>/dev/null) || {
        if [[ "$no_verify" == "true" ]]; then
            log_warning "Skipping verification (--no-verify)"
            checksums_content=""
        else
            log_error "Cannot fetch checksums — aborting (use --force --no-verify to skip)"
            exit 1
        fi
    }

    get_expected_checksum() {
        local filepath="$1"
        [[ -z "$checksums_content" ]] && { echo ""; return 0; }
        echo "$checksums_content" | grep -F "$filepath" | awk '{print $1}' | head -1 || true
    }

    verify_or_abort() {
        local file="$1" label="$2" checksum_key="$3"
        local expected
        expected=$(get_expected_checksum "$checksum_key") || true
        if [[ -n "$expected" ]]; then
            if verify_checksum "$file" "$expected"; then
                log_success "Checksum verified: $label"
            else
                log_error "Checksum mismatch for $label — file may be corrupted or tampered"
                return 1
            fi
        elif [[ -n "$checksums_content" ]]; then
            if [[ "$no_verify" == "true" ]]; then
                log_warning "No checksum entry for $label — skipping (--no-verify)"
            else
                log_error "No checksum entry for $label — aborting (use --force --no-verify to skip)"
                return 1
            fi
        fi
        return 0
    }

    # ── Phase 1: Fetch & verify all files into staging ──
    local staging_dir
    staging_dir="$(ensure_tmpdir)/update_staging"
    mkdir -p "$staging_dir/agents"
    local all_verified=true

    # Stage aishore script
    log_info "Fetching aishore..."
    if ! $fetch_cmd "$repo_url/.aishore/aishore" > "$staging_dir/aishore" 2>/dev/null; then
        log_error "Failed to fetch aishore script"
        exit 1
    fi
    if ! verify_or_abort "$staging_dir/aishore" "aishore" ".aishore/aishore"; then
        all_verified=false
    fi

    # Stage gitignore-entries.txt
    log_info "Fetching gitignore-entries.txt..."
    if $fetch_cmd "$repo_url/.aishore/gitignore-entries.txt" > "$staging_dir/gitignore-entries.txt" 2>/dev/null; then
        if ! verify_or_abort "$staging_dir/gitignore-entries.txt" "gitignore-entries.txt" ".aishore/gitignore-entries.txt"; then
            all_verified=false
        fi
    else
        log_error "Could not fetch gitignore-entries.txt"
        all_verified=false
    fi

    # Stage agent prompts
    for agent in developer validator tech-lead product-owner architect; do
        log_info "Fetching $agent.md..."
        if $fetch_cmd "$repo_url/.aishore/agents/$agent.md" > "$staging_dir/agents/$agent.md" 2>/dev/null; then
            if ! verify_or_abort "$staging_dir/agents/$agent.md" "$agent.md" ".aishore/agents/$agent.md"; then
                all_verified=false
            fi
        else
            log_error "Could not fetch $agent.md"
            all_verified=false
        fi
    done

    # ── Phase 2: Install (only if all verified) ──
    if [[ "$all_verified" != "true" ]]; then
        log_error "Verification failed — no files were modified"
        exit 1
    fi

    log_info "All files verified — installing..."
    mv "$staging_dir/aishore" "$AISHORE_ROOT/aishore"
    chmod +x "$AISHORE_ROOT/aishore"
    mv "$staging_dir/gitignore-entries.txt" "$AISHORE_ROOT/gitignore-entries.txt"
    for agent in developer validator tech-lead product-owner architect; do
        mv "$staging_dir/agents/$agent.md" "$AGENTS_DIR/$agent.md"
    done

    echo ""
    log_success "Updated to $remote_version (7 files installed)"
}

cmd_checksums() {
    cd "$PROJECT_ROOT"

    local checksum_file="$AISHORE_ROOT/checksums.sha256"
    local files=(
        .aishore/aishore
        .aishore/gitignore-entries.txt
    )

    # Add all agent prompts
    for f in "$AGENTS_DIR"/*.md; do
        [[ -f "$f" ]] && files+=(".aishore/agents/$(basename "$f")")
    done

    # Generate checksums
    local hash_cmd=()
    if command -v sha256sum &>/dev/null; then
        hash_cmd=(sha256sum)
    elif command -v shasum &>/dev/null; then
        hash_cmd=(shasum -a 256)
    else
        log_error "No sha256sum or shasum found"
        exit 1
    fi

    local tmp
    tmp="$(ensure_tmpdir)/checksums_gen.txt"
    for f in "${files[@]}"; do
        [[ -f "$f" ]] && "${hash_cmd[@]}" "$f" >> "$tmp"
    done

    mv "$tmp" "$checksum_file"
    log_success "Updated checksums.sha256 (${#files[@]} files)"
    cat "$checksum_file"
}

cmd_clean() {
    require_tool jq

    local dry_run=false
    while [[ $# -gt 0 ]]; do
        case "$1" in
            --dry-run) dry_run=true; shift ;;
            *) log_error "Unknown option: $1"; return 1 ;;
        esac
    done

    local feat_count=0 bug_count=0

    for source in backlog.json bugs.json; do
        local filepath="$BACKLOG_DIR/$source"
        [[ -f "$filepath" ]] || continue

        local count
        count=$(jq '[.items[] | select(.status == "done")] | length' "$filepath" 2>/dev/null || echo 0)

        if [[ "$source" == "backlog.json" ]]; then
            feat_count=$count
        else
            bug_count=$count
        fi

        if [[ "$dry_run" == "false" && "$count" -gt 0 ]]; then
            local tmp
            tmp="$(ensure_tmpdir)/clean_${source}"
            if jq '.items |= map(select(.status == "done" | not))' "$filepath" > "$tmp" 2>/dev/null; then
                mv "$tmp" "$filepath"
            else
                rm -f "$tmp"
                log_error "Failed to clean $source"
                return 1
            fi
        fi
    done

    local total=$((feat_count + bug_count))

    if [[ "$total" -eq 0 ]]; then
        echo "Nothing to clean"
    elif [[ "$dry_run" == "true" ]]; then
        echo "Would remove: $feat_count features, $bug_count bugs"
    else
        echo "Cleaned $feat_count features, $bug_count bugs ($total total removed)"
    fi
}

cmd_help() {
    cat << EOF
aishore - AI Sprint Runner (v$AISHORE_VERSION)

Usage: .aishore/aishore <command> [options]

Commands:
  run [count]       Run N sprints (default: 1)
  run <ID>          Run specific item by ID (e.g., TEST-006)
    --dry-run       Preview what would happen without running agents
    --auto-commit   Automatically commit after each sprint
    --retries N     Allow up to N retry attempts on validation failure

  groom             Groom bugs/tech debt (Tech Lead mode)
    --backlog       Groom features instead (Product Owner mode)

  review            Architecture review (read-only)
    --update-docs   Allow updates to docs
    --since <hash>  Review since specific commit

  metrics           Show sprint metrics
    --json          Output as JSON

  status            Show backlog overview and sprint readiness

  update            Update aishore from upstream
    --dry-run       Check for updates without applying
    --check         Alias for --dry-run
    --force         Update even if already on latest version
    --no-verify     Skip checksum verification (use with --force)

  clean             Remove done items from backlog and bugs
    --dry-run       Show what would be removed without changing files

  checksums         Regenerate checksums.sha256 for update verification
  init              Setup wizard — checks prerequisites, configures project
  version           Show version
  help              Show this help

Examples:
  .aishore/aishore run              # Run 1 sprint (auto-pick)
  .aishore/aishore run 5            # Run 5 sprints
  .aishore/aishore run TEST-006     # Run specific item
  .aishore/aishore run --dry-run        # Preview without running
  .aishore/aishore run --dry-run FEAT-002  # Preview specific item
  .aishore/aishore run --auto-commit 3
  .aishore/aishore run --retries 2    # Allow 2 retries on failure
  .aishore/aishore groom
  .aishore/aishore update --dry-run

Files:
  backlog/backlog.json    Your feature backlog (user content)
  backlog/bugs.json       Your bugs/tech debt (user content)
  backlog/sprint.json     Current sprint state
  .aishore/config.yaml    Optional configuration overrides
  .aishore/agents/        Agent prompts (updated by 'update')

Environment Variables:
  AISHORE_MODEL_PRIMARY     Primary model (default: claude-opus-4-6)
  AISHORE_MODEL_FAST        Fast model (default: claude-sonnet-4-6)
  AISHORE_AGENT_TIMEOUT     Agent timeout in seconds (default: 3600)
  AISHORE_VALIDATE_CMD      Validation command to run after implementation
  AISHORE_VALIDATE_TIMEOUT  Validation command timeout in seconds (default: 120)
  AISHORE_NOTIFY_CMD        Command to run on sprint completion (receives \$1=status, \$2=item_id)

Agent Permissions:
  Each agent role has a default permission set:
    developer       Bash(git:*),Edit,Write,Read,Glob,Grep
    validator       Bash(git:*),Read,Glob,Grep
    reviewer        Read,Glob,Grep  (with --update-docs: Read,Glob,Grep,Edit,Write)
    groom agents    Same as developer (they update backlog files)

  Override in config.yaml:
    permissions:
      developer: "Bash(git:*),Edit,Write,Read,Glob,Grep"
      validator: "Bash(git:*),Read,Glob,Grep"
      reviewer: "Read,Glob,Grep"

Trust Model:
  The 'update' command fetches from GitHub and verifies SHA-256 checksums.
  If checksums cannot be fetched, the update aborts unless --force --no-verify
  is passed. This ensures integrity but does NOT verify authorship — you trust
  the upstream repository and your network path to it.
EOF
}

# ============================================================================
# MAIN
# ============================================================================

main() {
    mkdir -p "$STATUS_DIR" "$LOGS_DIR" "$ARCHIVE_DIR"

    local cmd="${1:-help}"
    shift || true

    case "$cmd" in
        run)     cmd_run "$@" ;;
        groom)   cmd_groom "$@" ;;
        review)  cmd_review "$@" ;;
        metrics) cmd_metrics "$@" ;;
        status)  cmd_status "$@" ;;
        update)  cmd_update "$@" ;;
        checksums) cmd_checksums ;;
        clean)   cmd_clean "$@" ;;
        init)    cmd_init "$@" ;;
        version|-v|--version) cmd_version ;;
        help|-h|--help) cmd_help ;;
        *)
            log_error "Unknown command: $cmd"
            cmd_help
            exit 1
            ;;
    esac
}

main "$@"
